{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zarr\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import lightning.pytorch as pl\n",
    "from omegaconf import OmegaConf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingWarmRestarts\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, Callback\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "from main import ClimateEmulationDataModule, ClimateEmulationModule\n",
    "from _climate_kaggle_metric import score as kaggle_score\n",
    "\n",
    "from src.models import SimpleCNN\n",
    "from src.utils import convert_predictions_to_kaggle_format\n",
    "\n",
    "from temporal_data_module import TemporalDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/processed_data_cse151b_v2_corrupted_ssp245/processed_data_cse151b_v2_corrupted_ssp245.zarr'\n",
    "data = xr.open_zarr(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_batch_losses(train_losses, val_losses):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    plt.plot(train_losses, label=\"Train Loss (per batch)\", linewidth=0.8, alpha=0.8)\n",
    "    plt.plot(val_losses, label=\"Validation Loss (per batch)\", linewidth=0.8, alpha=0.8)\n",
    "\n",
    "    plt.xlabel(\"Batch (time)\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training and Validation Loss Over Time\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_epoch_losses(train_epoch_losses, val_epoch_losses):\n",
    "    epochs = range(1, len(train_epoch_losses) + 1)\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(epochs, train_epoch_losses, label='Train Loss (per epoch)', marker='o')\n",
    "    plt.plot(epochs, val_epoch_losses, label='Validation Loss (per epoch)', marker='s')\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training and Validation Loss per Epoch\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_top_mse_grid_points(y_pred_np, y_true_np, lat_coords, lon_coords, var_names, top_k=3):\n",
    "    T, C, H, W = y_true_np.shape\n",
    "    squared_error = (y_pred_np - y_true_np) ** 2\n",
    "\n",
    "    top_coords = []\n",
    "\n",
    "    for c in range(C):\n",
    "        var = var_names[int(c)]\n",
    "        var_error = squared_error[:, c, :, :]\n",
    "        flat_error = var_error.reshape(-1)\n",
    "        top_k_idx = np.argpartition(flat_error, -top_k)[-top_k:]\n",
    "        top_k_idx = top_k_idx[np.argsort(flat_error[top_k_idx])[::-1]]\n",
    "\n",
    "        for idx in top_k_idx:\n",
    "            t, h, w = np.unravel_index(idx, (T, H, W))\n",
    "            top_coords.append({\n",
    "                \"var\": var,\n",
    "                \"t\": int(t),\n",
    "                \"h\": int(h),\n",
    "                \"w\": int(w),\n",
    "                \"mse\": var_error[t, h, w].item()\n",
    "            })\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(np.zeros((H, W)), cmap='Greys', alpha=0.1)\n",
    "\n",
    "    color_map = {var: color for var, color in zip(var_names, ['red', 'blue', 'green', 'orange'])}\n",
    "\n",
    "    for entry in top_coords:\n",
    "        plt.scatter(entry[\"w\"], entry[\"h\"], color=color_map[entry[\"var\"]],\n",
    "                    s=100, edgecolors='black')\n",
    "\n",
    "    legend_elements = [\n",
    "        Line2D([0], [0], marker='o', color='w', label=var,\n",
    "               markerfacecolor=color_map[var], markersize=10, markeredgecolor='black')\n",
    "        for var in var_names\n",
    "    ]\n",
    "    plt.legend(handles=legend_elements)\n",
    "    plt.title(f\"Top {top_k} Highest MSE Grid Locations per Output Variable\")\n",
    "    plt.xlabel(\"Longitude Index (W)\")\n",
    "    plt.ylabel(\"Latitude Index (H)\")\n",
    "    plt.xlim(0, W - 1)\n",
    "    plt.ylim(H - 1, 0)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def area_weighted_climate_loss(y_pred, y_true, latitudes, var_type=\"tas\"):\n",
    "    \"\"\"\n",
    "    Custom loss approximating the competition score in a differentiable way.\n",
    "    \n",
    "    y_pred, y_true: tensors of shape [B, C, H, W]\n",
    "    latitudes: 1D tensor of shape [H] corresponding to each row\n",
    "    var_type: \"tas\" or \"pr\"\n",
    "    \"\"\"\n",
    "    B, C, H, W = y_true.shape\n",
    "\n",
    "    # 1. Create latitude weights [H] â†’ [H, 1]\n",
    "    lat_radians = torch.deg2rad(latitudes)\n",
    "    lat_weights = torch.cos(lat_radians)\n",
    "    lat_weights = lat_weights / lat_weights.sum()\n",
    "    lat_weights = lat_weights.view(1, 1, H, 1)  # broadcast to [B, C, H, W]\n",
    "\n",
    "    # 2. Area-weighted RMSE (per time step)\n",
    "    mse = F.mse_loss(y_pred, y_true, reduction='none')  # [B, C, H, W]\n",
    "    area_weighted_mse = (mse * lat_weights).mean()\n",
    "\n",
    "    # 3. Mean climate RMSE (mean over time, then spatial RMSE)\n",
    "    pred_mean = y_pred.mean(dim=0)  # [C, H, W]\n",
    "    true_mean = y_true.mean(dim=0)  # [C, H, W]\n",
    "    mean_mse = ((pred_mean - true_mean) ** 2 * lat_weights[0]).mean()\n",
    "\n",
    "    # 4. Std climate MAE (per location stddev over time)\n",
    "    pred_std = y_pred.std(dim=0)  # [C, H, W]\n",
    "    true_std = y_true.std(dim=0)  # [C, H, W]\n",
    "    std_mae = (torch.abs(pred_std - true_std) * lat_weights[0]).mean()\n",
    "\n",
    "    # 5. Combine with variable-specific weights\n",
    "    if var_type == \"tas\":\n",
    "        loss = 0.1 * torch.sqrt(area_weighted_mse) + 1.0 * torch.sqrt(mean_mse) + 1.0 * std_mae\n",
    "    elif var_type == \"pr\":\n",
    "        loss = 0.1 * torch.sqrt(area_weighted_mse) + 1.0 * torch.sqrt(mean_mse) + 0.75 * std_mae\n",
    "    else:\n",
    "        raise ValueError(\"var_type must be 'tas' or 'pr'\")\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock3D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout3d(dropout),\n",
    "\n",
    "            nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout3d(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "class ClimateUNet3D(nn.Module):\n",
    "    def __init__(self, in_channels=5, out_channels=2, base_channels=32, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.enc1 = ConvBlock3D(in_channels, base_channels, dropout)\n",
    "        self.pool1 = nn.MaxPool3d((1, 2, 2))\n",
    "\n",
    "        self.enc2 = ConvBlock3D(base_channels, base_channels * 2, dropout)\n",
    "        self.pool2 = nn.MaxPool3d((1, 2, 2))\n",
    "\n",
    "        self.enc3 = ConvBlock3D(base_channels * 2, base_channels * 4, dropout)\n",
    "        self.pool3 = nn.MaxPool3d((1, 2, 2))\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = ConvBlock3D(base_channels * 4, base_channels * 8, dropout)\n",
    "\n",
    "        # Decoder\n",
    "        self.up3 = nn.ConvTranspose3d(base_channels * 8, base_channels * 4, kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
    "        self.dec3 = ConvBlock3D(base_channels * 8, base_channels * 4, dropout)\n",
    "\n",
    "        self.up2 = nn.ConvTranspose3d(base_channels * 4, base_channels * 2, kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
    "        self.dec2 = ConvBlock3D(base_channels * 4, base_channels * 2, dropout)\n",
    "\n",
    "        self.up1 = nn.ConvTranspose3d(base_channels * 2, base_channels, kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
    "        self.dec1 = ConvBlock3D(base_channels * 2, base_channels, dropout)\n",
    "\n",
    "        # Final output\n",
    "        self.out_conv = nn.Conv3d(base_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1, 3, 4)  # [B, C, t, H, W]\n",
    "\n",
    "        # Encoder\n",
    "        e1 = self.enc1(x)\n",
    "        p1 = self.pool1(e1)\n",
    "\n",
    "        e2 = self.enc2(p1)\n",
    "        p2 = self.pool2(e2)\n",
    "\n",
    "        e3 = self.enc3(p2)\n",
    "        p3 = self.pool3(e3)\n",
    "\n",
    "        # Bottleneck\n",
    "        b = self.bottleneck(p3)\n",
    "\n",
    "        # Decoder\n",
    "        u3 = self.up3(b)\n",
    "        u3 = torch.cat([u3, e3], dim=1)\n",
    "        d3 = self.dec3(u3)\n",
    "\n",
    "        u2 = self.up2(d3)\n",
    "        u2 = torch.cat([u2, e2], dim=1)\n",
    "        d2 = self.dec2(u2)\n",
    "\n",
    "        u1 = self.up1(d2)\n",
    "        u1 = torch.cat([u1, e1], dim=1)\n",
    "        d1 = self.dec1(u1)\n",
    "\n",
    "        out = self.out_conv(d1)\n",
    "        out = out[:, :, -1]\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingMetrics(Callback):\n",
    "    def __init__(self):\n",
    "        self.train_epoch_losses = []\n",
    "        self.val_epoch_losses = []\n",
    "\n",
    "        self._train_losses = []\n",
    "        self._val_losses = []\n",
    "\n",
    "    def on_train_batch_end(self, trainer, pl_module, outputs, batch, batch_idx):\n",
    "        loss = outputs['loss'] if isinstance(outputs, dict) else outputs\n",
    "        self._train_losses.append(loss.item())\n",
    "\n",
    "    def on_validation_batch_end(self, trainer, pl_module, outputs, batch, batch_idx, dataloader_idx=0):\n",
    "        loss = outputs['loss'] if isinstance(outputs, dict) else outputs\n",
    "        self._val_losses.append(loss.item())\n",
    "\n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        if self._train_losses:\n",
    "            avg = sum(self._train_losses) / len(self._train_losses)\n",
    "            self.train_epoch_losses.append(avg)\n",
    "            self._train_losses.clear()\n",
    "\n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        if self._val_losses:\n",
    "            avg = sum(self._val_losses) / len(self._val_losses)\n",
    "            self.val_epoch_losses.append(avg)\n",
    "            self._val_losses.clear()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_temp = OmegaConf.create({\n",
    "    \"data\": {\n",
    "        \"path\": data_path,\n",
    "        \"input_vars\": [\"CO2\", \"CH4\", \"BC\", \"rsdt\"],\n",
    "        \"output_vars\": [\"tas\"],  # Only temperature\n",
    "        \"train_ssps\": [\"ssp126\", \"ssp370\", \"ssp585\"],\n",
    "        \"test_ssp\": \"ssp245\",\n",
    "        \"target_member_id\": 0,\n",
    "        \"batch_size\": 32,\n",
    "        \"num_workers\": 39,\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_precip = OmegaConf.create({\n",
    "    \"data\": {\n",
    "        \"path\": data_path,\n",
    "        \"input_vars\": [\"CO2\", \"CH4\", \"BC\", \"rsdt\"],\n",
    "        \"output_vars\": [\"pr\"],  # Only precipitation\n",
    "        \"train_ssps\": [\"ssp126\", \"ssp370\", \"ssp585\"],\n",
    "        \"test_ssp\": \"ssp245\",\n",
    "        \"target_member_id\": 0,\n",
    "        \"batch_size\": 32,\n",
    "        \"num_workers\": 39,\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module_temp = TemporalDataModule(**config_temp.data)\n",
    "data_module_temp.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module_precip = TemporalDataModule(**config_precip.data)\n",
    "data_module_precip.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature Model\n",
    "in_channels_temp = len(config_temp.data['input_vars']) + 1\n",
    "out_channels_temp = len(config_temp.data['output_vars'])\n",
    "\n",
    "model_temp = ClimateUNet3D(\n",
    "    base_channels=64,\n",
    "    in_channels=in_channels_temp,\n",
    "    out_channels=out_channels_temp\n",
    ")\n",
    "\n",
    "lightning_module_temp = ClimateEmulationModule(\n",
    "    model=model_temp,\n",
    "    learning_rate=5e-4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precipitation Model\n",
    "in_channels_precip = len(config_precip.data['input_vars']) + 1\n",
    "out_channels_precip = len(config_precip.data['output_vars'])\n",
    "\n",
    "model_precip = ClimateUNet3D(\n",
    "    base_channels=64,\n",
    "    in_channels=in_channels_precip,\n",
    "    out_channels=out_channels_precip\n",
    ")\n",
    "\n",
    "lightning_module_precip = ClimateEmulationModule(\n",
    "    model=model_precip,\n",
    "    learning_rate=5e-4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger_temp = TrainingMetrics()\n",
    "trainer_temp = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    accelerator='auto',\n",
    "    callbacks=[logger_temp]\n",
    ")\n",
    "\n",
    "trainer_temp.fit(lightning_module_temp, data_module_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logger_precip = TrainingMetrics()\n",
    "trainer_precip = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    accelerator='auto',\n",
    "    callbacks=[logger_precip]\n",
    ")\n",
    "\n",
    "trainer_precip.fit(lightning_module_precip, data_module_precip)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = logger_temp.train_epoch_losses\n",
    "val_losses = logger_temp.val_epoch_losses\n",
    "min_len = min(len(train_losses), len(val_losses))\n",
    "\n",
    "plot_epoch_losses(train_losses[:min_len], val_losses[:min_len])\n",
    "\n",
    "# trainer_temp.test(lightning_module_temp, data_module_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = logger_precip.train_epoch_losses\n",
    "val_losses = logger_precip.val_epoch_losses\n",
    "min_len = min(len(train_losses), len(val_losses))\n",
    "\n",
    "plot_epoch_losses(train_losses[:min_len], val_losses[:min_len])\n",
    "\n",
    "# trainer_precip.test(lightning_module_precip, data_module_precip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Produce Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightning_module_temp.eval()\n",
    "all_preds_temp = []\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_temp = lightning_module_temp.model.to(device)\n",
    "\n",
    "for x, y_true in data_module_temp.test_dataloader():\n",
    "    x = x.to(device)\n",
    "    with torch.no_grad():\n",
    "        y_pred = model_temp(x.to(device)).squeeze(0)\n",
    "        all_preds_temp.append(y_pred.cpu().numpy())\n",
    "\n",
    "y_pred_np_temp = np.concatenate(all_preds_temp, axis=0)\n",
    "y_pred_output_temp = data_module_temp.normalizer.inverse_transform_output(y_pred_np_temp)\n",
    "\n",
    "lat_coords, lon_coords = data_module_temp.get_coords()\n",
    "time_coords = np.arange(y_pred_np_temp.shape[0])\n",
    "var_names_temp = config_temp.data['output_vars']\n",
    "\n",
    "submission_temp = convert_predictions_to_kaggle_format(\n",
    "    y_pred_output_temp, time_coords, lat_coords, lon_coords, var_names_temp\n",
    ")\n",
    "\n",
    "submission_temp.to_csv(\"submission_temp.csv\", index=False)\n",
    "\n",
    "lightning_module_precip.eval()\n",
    "all_preds_precip = []\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_precip = lightning_module_precip.model.to(device)\n",
    "\n",
    "for x, y_true in data_module_precip.test_dataloader():\n",
    "    x = x.to(device)\n",
    "    with torch.no_grad():\n",
    "        y_pred = model_precip(x.to(device)).squeeze(0)\n",
    "        all_preds_precip.append(y_pred.cpu().numpy())\n",
    "\n",
    "y_pred_np_precip = np.concatenate(all_preds_precip, axis=0)\n",
    "y_pred_output_precip = data_module_precip.normalizer.inverse_transform_output(y_pred_np_precip)\n",
    "\n",
    "lat_coords, lon_coords = data_module_precip.get_coords()\n",
    "time_coords = np.arange(y_pred_np_precip.shape[0])\n",
    "var_names_precip = config_precip.data['output_vars']\n",
    "\n",
    "submission_precip = convert_predictions_to_kaggle_format(\n",
    "    y_pred_output_precip, time_coords, lat_coords, lon_coords, var_names_precip\n",
    ")\n",
    "\n",
    "submission_precip.to_csv(\"submission_precip.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_final = pd.concat([submission_temp, submission_precip], axis=0)\n",
    "submission_final.to_csv(\"submission_final.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
