{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda8ff4c-916f-4949-824b-57adc3524315",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zarr\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import lightning.pytorch as pl\n",
    "from omegaconf import OmegaConf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingWarmRestarts\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, Callback\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "from main import ClimateEmulationDataModule, ClimateEmulationModule\n",
    "from _climate_kaggle_metric import score as kaggle_score\n",
    "\n",
    "from src.models import SimpleCNN\n",
    "from src.climate_3d_cnn import ClimateEmulator3D\n",
    "from src.utils import convert_predictions_to_kaggle_format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37dba9cc-f5a4-4a43-ad4a-80832cf2cabd",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4dbb42-646e-451f-9932-844e4159ae74",
   "metadata": {},
   "source": [
    "### Module with Elastic Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b558ec-8ad4-4fe9-9a4b-f99f3636987e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElasticClimateModule(ClimateEmulationModule):\n",
    "    def __init__(self, model: nn.Module, learning_rate: float, lambda_l1: float = 1e-6, lambda_l2: float = 1e-4):\n",
    "        super().__init__(model=model, learning_rate=learning_rate)\n",
    "        self.lambda_l1 = lambda_l1\n",
    "        self.lambda_l2 = lambda_l2\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y_true_norm = batch\n",
    "        y_pred_norm = self(x)\n",
    "        loss = self.criterion(y_pred_norm, y_true_norm)\n",
    "\n",
    "        # Elastic Net Regularization\n",
    "        l1_penalty = sum(p.abs().sum() for p in self.model.parameters())\n",
    "        l2_penalty = sum((p ** 2).sum() for p in self.model.parameters())\n",
    "        reg_loss = self.lambda_l1 * l1_penalty + self.lambda_l2 * l2_penalty\n",
    "\n",
    "        total_loss = loss + reg_loss\n",
    "\n",
    "        self.log(\"train/loss\", total_loss, prog_bar=True, batch_size=x.size(0))\n",
    "        self.log(\"train/loss_core\", loss, prog_bar=False, batch_size=x.size(0))\n",
    "        self.log(\"train/loss_l1\", self.lambda_l1 * l1_penalty, prog_bar=False, batch_size=x.size(0))\n",
    "        self.log(\"train/loss_l2\", self.lambda_l2 * l2_penalty, prog_bar=False, batch_size=x.size(0))\n",
    "\n",
    "        return total_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e0d33d-46a7-4216-b59e-b4d1484d6b34",
   "metadata": {},
   "source": [
    "### UNet 3D Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd4c45a-8e5d-4c1a-8f27-0527dadf9352",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock3D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout3d(dropout),\n",
    "\n",
    "            nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout3d(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "class ClimateUNet3D(nn.Module):\n",
    "    def __init__(self, in_channels=5, out_channels=2, base_channels=32, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.enc1 = ConvBlock3D(in_channels, base_channels, dropout)\n",
    "        self.pool1 = nn.MaxPool3d((1, 2, 2))\n",
    "\n",
    "        self.enc2 = ConvBlock3D(base_channels, base_channels * 2, dropout)\n",
    "        self.pool2 = nn.MaxPool3d((1, 2, 2))\n",
    "\n",
    "        self.enc3 = ConvBlock3D(base_channels * 2, base_channels * 4, dropout)\n",
    "        self.pool3 = nn.MaxPool3d((1, 2, 2))\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = ConvBlock3D(base_channels * 4, base_channels * 8, dropout)\n",
    "\n",
    "        # Decoder\n",
    "        self.up3 = nn.ConvTranspose3d(base_channels * 8, base_channels * 4, kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
    "        self.dec3 = ConvBlock3D(base_channels * 8, base_channels * 4, dropout)\n",
    "\n",
    "        self.up2 = nn.ConvTranspose3d(base_channels * 4, base_channels * 2, kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
    "        self.dec2 = ConvBlock3D(base_channels * 4, base_channels * 2, dropout)\n",
    "\n",
    "        self.up1 = nn.ConvTranspose3d(base_channels * 2, base_channels, kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
    "        self.dec1 = ConvBlock3D(base_channels * 2, base_channels, dropout)\n",
    "\n",
    "        # Final output\n",
    "        self.out_conv = nn.Conv3d(base_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(2)\n",
    "\n",
    "        # Encoder\n",
    "        e1 = self.enc1(x)\n",
    "        p1 = self.pool1(e1)\n",
    "\n",
    "        e2 = self.enc2(p1)\n",
    "        p2 = self.pool2(e2)\n",
    "\n",
    "        e3 = self.enc3(p2)\n",
    "        p3 = self.pool3(e3)\n",
    "\n",
    "        # Bottleneck\n",
    "        b = self.bottleneck(p3)\n",
    "\n",
    "        # Decoder\n",
    "        u3 = self.up3(b)\n",
    "        u3 = torch.cat([u3, e3], dim=1)\n",
    "        d3 = self.dec3(u3)\n",
    "\n",
    "        u2 = self.up2(d3)\n",
    "        u2 = torch.cat([u2, e2], dim=1)\n",
    "        d2 = self.dec2(u2)\n",
    "\n",
    "        u1 = self.up1(d2)\n",
    "        u1 = torch.cat([u1, e1], dim=1)\n",
    "        d1 = self.dec1(u1)\n",
    "\n",
    "        out = self.out_conv(d1)\n",
    "        return out.squeeze(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1046561c-109c-4184-b685-9b7e4e738600",
   "metadata": {},
   "source": [
    "### Training Callback Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9eab0c2-33b5-475a-adaa-224d31dc46e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingMetrics(Callback):\n",
    "    def __init__(self):\n",
    "        self.train_epoch_losses = []\n",
    "        self.val_epoch_losses = []\n",
    "\n",
    "        self._train_losses = []\n",
    "        self._val_losses = []\n",
    "\n",
    "    def on_train_batch_end(self, trainer, pl_module, outputs, batch, batch_idx):\n",
    "        loss = outputs['loss'] if isinstance(outputs, dict) else outputs\n",
    "        self._train_losses.append(loss.item())\n",
    "\n",
    "    def on_validation_batch_end(self, trainer, pl_module, outputs, batch, batch_idx, dataloader_idx=0):\n",
    "        loss = outputs['loss'] if isinstance(outputs, dict) else outputs\n",
    "        self._val_losses.append(loss.item())\n",
    "\n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        if self._train_losses:\n",
    "            avg = sum(self._train_losses) / len(self._train_losses)\n",
    "            self.train_epoch_losses.append(avg)\n",
    "            self._train_losses.clear()\n",
    "\n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        if self._val_losses:\n",
    "            avg = sum(self._val_losses) / len(self._val_losses)\n",
    "            self.val_epoch_losses.append(avg)\n",
    "            self._val_losses.clear()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ef6c9e-c566-472a-90c1-5cfd4ae27a2c",
   "metadata": {},
   "source": [
    "### Plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f91f88-68bf-4b2c-bad6-a5d75802b45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_batch_losses(train_losses, val_losses):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    plt.plot(train_losses, label=\"Train Loss (per batch)\", linewidth=0.8, alpha=0.8)\n",
    "    plt.plot(val_losses, label=\"Validation Loss (per batch)\", linewidth=0.8, alpha=0.8)\n",
    "\n",
    "    plt.xlabel(\"Batch (time)\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training and Validation Loss Over Time\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_epoch_losses(train_epoch_losses, val_epoch_losses):\n",
    "    epochs = range(1, len(train_epoch_losses) + 1)\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(epochs, train_epoch_losses, label='Train Loss (per epoch)', marker='o')\n",
    "    plt.plot(epochs, val_epoch_losses, label='Validation Loss (per epoch)', marker='s')\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training and Validation Loss per Epoch\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_top_mse_grid_points(y_pred_np, y_true_np, lat_coords, lon_coords, var_names, top_k=3):\n",
    "    T, C, H, W = y_true_np.shape\n",
    "    squared_error = (y_pred_np - y_true_np) ** 2\n",
    "\n",
    "    top_coords = []\n",
    "\n",
    "    for c in range(C):\n",
    "        var = var_names[int(c)]\n",
    "        var_error = squared_error[:, c, :, :]\n",
    "        flat_error = var_error.reshape(-1)\n",
    "        top_k_idx = np.argpartition(flat_error, -top_k)[-top_k:]\n",
    "        top_k_idx = top_k_idx[np.argsort(flat_error[top_k_idx])[::-1]]\n",
    "\n",
    "        for idx in top_k_idx:\n",
    "            t, h, w = np.unravel_index(idx, (T, H, W))\n",
    "            top_coords.append({\n",
    "                \"var\": var,\n",
    "                \"t\": int(t),\n",
    "                \"h\": int(h),\n",
    "                \"w\": int(w),\n",
    "                \"mse\": var_error[t, h, w].item()\n",
    "            })\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(np.zeros((H, W)), cmap='Greys', alpha=0.1)\n",
    "\n",
    "    color_map = {var: color for var, color in zip(var_names, ['red', 'blue', 'green', 'orange'])}\n",
    "\n",
    "    for entry in top_coords:\n",
    "        plt.scatter(entry[\"w\"], entry[\"h\"], color=color_map[entry[\"var\"]],\n",
    "                    s=100, edgecolors='black')\n",
    "\n",
    "    legend_elements = [\n",
    "        Line2D([0], [0], marker='o', color='w', label=var,\n",
    "               markerfacecolor=color_map[var], markersize=10, markeredgecolor='black')\n",
    "        for var in var_names\n",
    "    ]\n",
    "    plt.legend(handles=legend_elements)\n",
    "    plt.title(f\"Top {top_k} Highest MSE Grid Locations per Output Variable\")\n",
    "    plt.xlabel(\"Longitude Index (W)\")\n",
    "    plt.ylabel(\"Latitude Index (H)\")\n",
    "    plt.xlim(0, W - 1)\n",
    "    plt.ylim(H - 1, 0)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693f5163-0715-4a2a-b681-72984349d0c3",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db562269-4742-476e-bc2d-35c01a7c5894",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/processed_data_cse151b_v2_corrupted_ssp245.zarr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389e3000-3349-44c2-bf9f-27c4a8c247d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = OmegaConf.create({\n",
    "    \"data\": {\n",
    "        \"path\": data_path,\n",
    "        \"input_vars\": [\"CO2\", \"SO2\", \"CH4\", \"BC\", \"rsdt\"],\n",
    "        # \"input_vars\": [\"CO2\", \"CH4\", \"BC\", \"rsdt\"],\n",
    "        \"output_vars\": [\"tas\", \"pr\"],\n",
    "        \"train_ssps\": [\"ssp126\", \"ssp370\", \"ssp585\"],\n",
    "        \"test_ssp\": \"ssp245\",\n",
    "        \"target_member_id\": 0,\n",
    "        \"batch_size\": 32,\n",
    "        \"num_workers\": 39,\n",
    "        \n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88a7f6d-6faa-427e-80b2-8d3e1717433c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = ClimateEmulationDataModule(**config.data)\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2919c815-eb84-41ab-b7e5-b9eeb5eea462",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = len(config.data['input_vars'])\n",
    "out_channels = len(config.data['output_vars'])\n",
    "\n",
    "model = ClimateUNet3D(base_channels=64, in_channels=in_channels, out_channels=out_channels)\n",
    "\n",
    "lightning_module=ClimateEmulationModule(\n",
    "    model = model,\n",
    "    learning_rate = 5e-4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d0ce82-ea51-46b4-90d3-5ab891b531ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = TrainingMetrics()\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=20,\n",
    "    accelerator='auto',\n",
    "    callbacks=[logger]    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85622038-d0cd-438b-8f18-d704637f8180",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.fit(lightning_module, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e917fe28-11fa-4cdb-891b-1ca340c08ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = logger.train_epoch_losses\n",
    "val_losses = logger.val_epoch_losses\n",
    "min_len = min(len(train_losses), len(val_losses))\n",
    "\n",
    "plot_epoch_losses(train_losses[:min_len], val_losses[:min_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69c1695-1b6c-4f50-80e5-fea94f2c310d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(lightning_module, data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f7d6e1-5759-4075-be7a-cec45c3a0ec8",
   "metadata": {},
   "source": [
    "## Produce Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8257f50-0876-4a4a-a944-a89246ead10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "all_preds = []\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "for x, y_true in data_module.test_dataloader():\n",
    "    x = x.to(device)\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(x.to(device)).squeeze(0)\n",
    "    all_preds.append(y_pred.cpu().numpy())\n",
    "\n",
    "y_pred_np = np.concatenate(all_preds, axis=0)\n",
    "y_pred_output = data_module.normalizer.inverse_transform_output(y_pred_np)\n",
    "\n",
    "lat_coords, lon_coords = data_module.get_coords()\n",
    "time_coords = np.arange(y_pred_np.shape[0])\n",
    "var_names = config.data['output_vars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9869b6f-31ff-4dc7-83a0-d983ad942a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = convert_predictions_to_kaggle_format(\n",
    "    y_pred_output, time_coords, lat_coords, lon_coords, var_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f177e26d-62d4-4ccc-b3cb-e46d83d204bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(submission_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0d7dfd-f3c5-42b1-9e5a-dc892d38cd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2841040e-5c6f-4bd2-b4ac-a6cdf5074133",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579bbc55-eb73-49f6-84e9-3fce51dd4867",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "all_preds = []\n",
    "all_trues = []\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "for x, y_true in data_module.train_dataloader():\n",
    "    x = x.to(device)\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(x.to(device)).squeeze(0)\n",
    "    all_preds.append(y_pred.cpu().numpy())\n",
    "    all_trues.append(y_true.cpu().numpy())\n",
    "    \n",
    "y_pred_np = np.concatenate(all_preds, axis=0)\n",
    "y_true_np = np.concatenate(all_trues, axis=0)\n",
    "\n",
    "lat_coords, lon_coords = data_module.get_coords()\n",
    "var_names = config.data['output_vars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98f0160-7795-4e0e-a7d4-801ba2bb3808",
   "metadata": {},
   "outputs": [],
   "source": [
    "T, C, H, W = squared_error.shape\n",
    "top_k = 3\n",
    "\n",
    "top_coords = []\n",
    "\n",
    "for c in range(C):\n",
    "    var = var_names[int(c)]\n",
    "    var_error = squared_error[:, c, :, :]\n",
    "\n",
    "    flat_error = var_error.reshape(-1)\n",
    "    top_k_idx = np.argpartition(flat_error, -top_k)[-top_k:]\n",
    "    top_k_idx = top_k_idx[np.argsort(flat_error[top_k_idx])[::-1]]\n",
    "\n",
    "    for idx in top_k_idx:\n",
    "        t, h, w = np.unravel_index(idx, (T, H, W))\n",
    "        top_coords.append({\n",
    "            \"time\": int(t),\n",
    "            \"h\": int(h),\n",
    "            \"w\": int(w),\n",
    "            \"var\": var,\n",
    "            \"mse\": var_error[t, h, w].item()\n",
    "        })\n",
    "top_coords_df = pd.DataFrame(top_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bdb787-9e3f-41c3-8db9-33742bbed95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_top_mse_grid_points(\n",
    "    y_pred_np=y_pred_np,\n",
    "    y_true_np=y_true_np,\n",
    "    lat_coords=lat_coords,\n",
    "    lon_coords=lon_coords,\n",
    "    var_names=config.data['output_vars'],\n",
    "    top_k=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b61d18-fa81-466f-80f2-d158eca4f935",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
