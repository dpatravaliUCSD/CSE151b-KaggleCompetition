{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cda8ff4c-916f-4949-824b-57adc3524315",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import zarr\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import lightning.pytorch as pl\n",
    "from omegaconf import OmegaConf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingWarmRestarts\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "from main import ClimateEmulationDataModule, ClimateEmulationModule\n",
    "from _climate_kaggle_metric import score as kaggle_score\n",
    "\n",
    "from src.models import SimpleCNN\n",
    "from src.utils import convert_predictions_to_kaggle_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db562269-4742-476e-bc2d-35c01a7c5894",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/processed_data_cse151b_v2_corrupted_ssp245.zarr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "389e3000-3349-44c2-bf9f-27c4a8c247d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = OmegaConf.create({\n",
    "    \"data\": {\n",
    "        \"path\": data_path,\n",
    "        \"input_vars\": [\"CO2\", \"SO2\", \"CH4\", \"BC\", \"rsdt\"],\n",
    "        \"output_vars\": [\"tas\", \"pr\"],\n",
    "        \"train_ssps\": [\"ssp126\", \"ssp370\", \"ssp585\"],\n",
    "        \"test_ssp\": \"ssp245\",\n",
    "        \"target_member_id\": 0,\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"lr\": 1e-3,\n",
    "        \"weight_decay\": 1e-5,\n",
    "        \"max_epochs\": 3,\n",
    "        \"early_stopping_patience\": 10,\n",
    "        \"gradient_clip_val\": 1.0,\n",
    "        \"accumulate_grad_batches\": 1\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e88a7f6d-6faa-427e-80b2-8d3e1717433c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = ClimateEmulationDataModule(**config.data)\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25eae813-2739-4ef6-bab2-8adafd6cf17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = SimpleCNN(\n",
    "#     n_input_channels = len(config.data['input_vars']),\n",
    "#     n_output_channels = len(config.data['output_vars'])\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a54d200-7847-4126-b45c-fc2fef7a3f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock3D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, downsample=True, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.downsample = downsample\n",
    "        \n",
    "        self.conv1 = nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm3d(out_channels)\n",
    "        self.dropout1 = nn.Dropout3d(p=dropout_rate)\n",
    "        \n",
    "        self.conv2 = nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm3d(out_channels)\n",
    "        self.dropout2 = nn.Dropout3d(p=dropout_rate)\n",
    "        \n",
    "        # Downsample conv (if needed)\n",
    "        if downsample:\n",
    "            self.down = nn.Conv3d(out_channels, out_channels, kernel_size=(1,3,3), \n",
    "                                padding=(0,1,1), stride=(1,2,2))\n",
    "        \n",
    "        # Residual connection\n",
    "        self.residual = nn.Conv3d(in_channels, out_channels, kernel_size=1) if in_channels != out_channels else nn.Identity()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = self.residual(x)\n",
    "        \n",
    "        # Main path\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.leaky_relu(x, negative_slope=0.2)  # LeakyReLU instead of ReLU\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.leaky_relu(x, negative_slope=0.2)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        # Add residual\n",
    "        x = x + identity\n",
    "        \n",
    "        # Store pre-downsample output for skip connection\n",
    "        skip = x\n",
    "        \n",
    "        # Downsample if needed\n",
    "        if self.downsample:\n",
    "            x = self.down(x)\n",
    "        \n",
    "        return x, skip\n",
    "\n",
    "class DecoderBlock3D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, upsample=True, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.upsample = upsample\n",
    "        \n",
    "        # Upsample conv (if needed)\n",
    "        if upsample:\n",
    "            self.up = nn.ConvTranspose3d(in_channels, in_channels, kernel_size=(1,3,3),\n",
    "                                       padding=(0,1,1), stride=(1,2,2), output_padding=(0,1,1))\n",
    "        \n",
    "        # First convolution block (after concatenation)\n",
    "        self.conv1 = nn.Conv3d(in_channels * 2, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm3d(out_channels)\n",
    "        self.dropout1 = nn.Dropout3d(p=dropout_rate)\n",
    "        \n",
    "        # Second convolution block\n",
    "        self.conv2 = nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm3d(out_channels)\n",
    "        self.dropout2 = nn.Dropout3d(p=dropout_rate)\n",
    "        \n",
    "    def forward(self, x, skip=None):\n",
    "        # Upsample if needed\n",
    "        if self.upsample:\n",
    "            x = self.up(x)\n",
    "        \n",
    "        # Concatenate skip connection if provided\n",
    "        if skip is not None:\n",
    "            x = torch.cat([x, skip], dim=1)\n",
    "        \n",
    "        # Main path\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.leaky_relu(x, negative_slope=0.2)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.leaky_relu(x, negative_slope=0.2)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class EncoderDecoder3DCNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_input_channels=5,\n",
    "        n_output_channels=2,\n",
    "        base_channels=64,\n",
    "        dropout_rate=0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Store n_output_channels as instance variable\n",
    "        self.n_output_channels = n_output_channels\n",
    "        \n",
    "        # Encoder\n",
    "        self.enc1 = EncoderBlock3D(n_input_channels, base_channels, downsample=True, dropout_rate=dropout_rate)\n",
    "        self.enc2 = EncoderBlock3D(base_channels, base_channels * 2, downsample=True, dropout_rate=dropout_rate)\n",
    "        self.enc3 = EncoderBlock3D(base_channels * 2, base_channels * 4, downsample=False, dropout_rate=dropout_rate)\n",
    "        \n",
    "        # Enhanced Bottleneck with dropout\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv3d(base_channels * 4, base_channels * 8, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(base_channels * 8),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "            nn.Dropout3d(p=dropout_rate),\n",
    "            \n",
    "            nn.Conv3d(base_channels * 8, base_channels * 8, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(base_channels * 8),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "            nn.Dropout3d(p=dropout_rate),\n",
    "            \n",
    "            nn.Conv3d(base_channels * 8, base_channels * 4, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(base_channels * 4),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "            nn.Dropout3d(p=dropout_rate)\n",
    "        )\n",
    "        \n",
    "        # Decoder\n",
    "        self.dec3 = DecoderBlock3D(base_channels * 4, base_channels * 2, upsample=False, dropout_rate=dropout_rate)\n",
    "        self.dec2 = DecoderBlock3D(base_channels * 2, base_channels, upsample=True, dropout_rate=dropout_rate)\n",
    "        self.dec1 = DecoderBlock3D(base_channels, base_channels, upsample=True, dropout_rate=dropout_rate)\n",
    "        \n",
    "        # Final layers - simplified to ensure exact number of output channels\n",
    "        self.final_conv = nn.Sequential(\n",
    "            nn.Conv3d(base_channels, base_channels // 2, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(base_channels // 2),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "            nn.Dropout3d(p=dropout_rate/2),\n",
    "            nn.Conv3d(base_channels // 2, n_output_channels, kernel_size=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Add batch dimension if not present\n",
    "        if len(x.shape) == 4:\n",
    "            x = x.unsqueeze(0)\n",
    "            \n",
    "        # Rearrange from [B, D, C, H, W] to [B, C, D, H, W]\n",
    "        x = x.permute(0, 2, 1, 3, 4)\n",
    "        \n",
    "        # Store input shape for debugging\n",
    "        input_shape = x.shape\n",
    "        \n",
    "        # Encoder\n",
    "        x, skip1 = self.enc1(x)\n",
    "        x, skip2 = self.enc2(x)\n",
    "        x, skip3 = self.enc3(x)\n",
    "        \n",
    "        # Bottleneck\n",
    "        x = self.bottleneck(x)\n",
    "        \n",
    "        # Decoder (with skip connections)\n",
    "        x = self.dec3(x, skip3)\n",
    "        x = self.dec2(x, skip2)\n",
    "        x = self.dec1(x, skip1)\n",
    "        \n",
    "        # Final convolutions\n",
    "        x = self.final_conv(x)\n",
    "        \n",
    "        # Verify output channels match expected number\n",
    "        assert x.shape[1] == self.n_output_channels, f\"Expected {self.n_output_channels} output channels but got {x.shape[1]}\"\n",
    "        \n",
    "        # Verify output spatial dimensions match input\n",
    "        assert x.shape[-3:] == input_shape[-3:], f\"Output shape {x.shape} doesn't match input shape {input_shape}\"\n",
    "        \n",
    "        # Permute back to original format [B, D, C, H, W]\n",
    "        x = x.permute(0, 2, 1, 3, 4)\n",
    "        \n",
    "        # Remove batch dimension if it was added\n",
    "        if len(input_shape) == 4:\n",
    "            x = x.squeeze(0)\n",
    "            \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f6d6645-5132-4a21-9093-4de1a3d9cfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myLightningModule(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        learning_rate: float = 1e-3,\n",
    "        weight_decay: float = 0.01,\n",
    "        scheduler_type: str = 'plateau'  # 'plateau' or 'cosine'\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.save_hyperparameters(ignore=[\"model\"])\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.normalizer = None\n",
    "        self.training_step_outputs = []\n",
    "        self.current_epoch_losses = []\n",
    "        self.validation_step_outputs = []\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def on_fit_start(self):\n",
    "        self.normalizer = self.trainer.datamodule.normalizer\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y_true_norm = batch\n",
    "        y_pred_norm = self(x)\n",
    "        loss = self.criterion(y_pred_norm, y_true_norm)\n",
    "        \n",
    "        # Store loss for epoch end logging\n",
    "        self.current_epoch_losses.append(loss.item())\n",
    "        \n",
    "        # Log loss and learning rate\n",
    "        self.log(\"train/loss\", loss, prog_bar=True, batch_size=x.size(0))\n",
    "        self.log(\"train/lr\", self.optimizers().param_groups[0]['lr'], prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        # Calculate and print average loss for the epoch\n",
    "        avg_loss = np.mean(self.current_epoch_losses)\n",
    "        print(f\"\\nEpoch {self.current_epoch} - Average training loss: {avg_loss:.6f}\")\n",
    "        self.current_epoch_losses = []  # Reset for next epoch\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y_true_norm = batch\n",
    "        y_pred_norm = self(x)\n",
    "        loss = self.criterion(y_pred_norm, y_true_norm)\n",
    "        \n",
    "        # Store predictions for epoch end calculations\n",
    "        self.validation_step_outputs.append({\n",
    "            'loss': loss.item(),\n",
    "            'y_pred': y_pred_norm.detach(),\n",
    "            'y_true': y_true_norm.detach()\n",
    "        })\n",
    "        \n",
    "        # Log validation loss\n",
    "        self.log(\"val/loss\", loss, prog_bar=True, batch_size=x.size(0), sync_dist=True)\n",
    "        return loss\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        # Calculate average validation loss\n",
    "        val_losses = [x['loss'] for x in self.validation_step_outputs]\n",
    "        avg_val_loss = np.mean(val_losses)\n",
    "        \n",
    "        # Log validation metrics\n",
    "        self.log(\"val/avg_loss\", avg_val_loss, prog_bar=True)\n",
    "        \n",
    "        # Clear stored outputs\n",
    "        self.validation_step_outputs.clear()\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        # Create optimizer with weight decay\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            self.parameters(),\n",
    "            lr=self.hparams.learning_rate,\n",
    "            weight_decay=self.hparams.weight_decay\n",
    "        )\n",
    "        \n",
    "        # Configure scheduler\n",
    "        if self.hparams.scheduler_type == 'plateau':\n",
    "            scheduler = {\n",
    "                'scheduler': ReduceLROnPlateau(\n",
    "                    optimizer,\n",
    "                    mode='min',\n",
    "                    factor=0.5,\n",
    "                    patience=5,\n",
    "                    verbose=True\n",
    "                ),\n",
    "                'monitor': 'val/loss',\n",
    "                'interval': 'epoch',\n",
    "                'frequency': 1\n",
    "            }\n",
    "        else:  # cosine\n",
    "            scheduler = {\n",
    "                'scheduler': CosineAnnealingWarmRestarts(\n",
    "                    optimizer,\n",
    "                    T_0=10,  # Restart every 10 epochs\n",
    "                    T_mult=2,  # Double the restart interval after each restart\n",
    "                    eta_min=1e-6  # Minimum learning rate\n",
    "                ),\n",
    "                'interval': 'epoch',\n",
    "                'frequency': 1\n",
    "            }\n",
    "        \n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': scheduler\n",
    "        } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acbfe725-0876-421e-9ab2-3c30d5abf388",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EncoderDecoder3DCNN(\n",
    "    n_input_channels=5,\n",
    "    n_output_channels=2,\n",
    "    base_channels=64,\n",
    "    dropout_rate=0.15\n",
    ")\n",
    "lightning_module = myLightningModule(\n",
    "    model=model,\n",
    "    learning_rate=5e-4,\n",
    "    weight_decay=0.01,\n",
    "    scheduler_type='cosine'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11117bed-c03d-4303-8953-31497334db9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=5,\n",
    "    accelerator='auto',\n",
    "    devices=1,\n",
    "    callbacks=[\n",
    "        pl.callbacks.EarlyStopping(\n",
    "            monitor='val/loss',\n",
    "            patience=10,\n",
    "            mode='min'\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62d0ce82-ea51-46b4-90d3-5ab891b531ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA A30 MIG 2g.12gb') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "2025-05-15 05:16:33.646043: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747286193.661353    1329 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747286193.666213    1329 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-15 05:16:33.683850: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type                | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | model     | EncoderDecoder3DCNN | 21.2 M | train\n",
      "1 | criterion | MSELoss             | 0      | train\n",
      "----------------------------------------------------------\n",
      "21.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "21.2 M    Total params\n",
      "84.654    Total estimated model params size (MB)\n",
      "70        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a4shi/.local/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=63` in the `DataLoader` to improve performance.\n",
      "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([32, 2, 48, 72])) that is different to the input size (torch.Size([1, 32, 2, 48, 72])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/a4shi/.local/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=63` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bc2a80379a14c24ac0b7ff249992175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([31, 2, 48, 72])) that is different to the input size (torch.Size([1, 31, 2, 48, 72])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([24, 2, 48, 72])) that is different to the input size (torch.Size([1, 24, 2, 48, 72])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0 - Average training loss: 0.501503\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 - Average training loss: 0.366051\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 - Average training loss: 0.336115\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3 - Average training loss: 0.327124\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4 - Average training loss: 0.316043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(lightning_module, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8257f50-0876-4a4a-a944-a89246ead10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "all_preds = []\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "for x, y_true in data_module.test_dataloader():\n",
    "    x = x.to(device)\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(x.to(device)).squeeze(0)\n",
    "    all_preds.append(y_pred.cpu().numpy())\n",
    "\n",
    "y_pred_np = np.concatenate(all_preds, axis=0)\n",
    "y_pred_output = data_module.normalizer.inverse_transform_output(y_pred_np)\n",
    "\n",
    "lat_coords, lon_coords = data_module.get_coords()\n",
    "time_coords = np.arange(y_pred_np.shape[0])\n",
    "var_names = config.data['output_vars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9869b6f-31ff-4dc7-83a0-d983ad942a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = convert_predictions_to_kaggle_format(\n",
    "    y_pred_output, time_coords, lat_coords, lon_coords, var_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f177e26d-62d4-4ccc-b3cb-e46d83d204bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2488320, 2)\n"
     ]
    }
   ],
   "source": [
    "print(submission_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e0d7dfd-f3c5-42b1-9e5a-dc892d38cd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
