{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620daa2d-ebae-4868-bcf6-664987471cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import lightning.pytorch as pl\n",
    "from omegaconf import OmegaConf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "from main import ClimateEmulationDataModule, ClimateEmulationModule\n",
    "from _climate_kaggle_metric import score as kaggle_score\n",
    "\n",
    "from src.models import SimpleCNN\n",
    "from src.utils import convert_predictions_to_kaggle_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db562269-4742-476e-bc2d-35c01a7c5894",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/processed_data_cse151b_v2_corrupted_ssp245.zarr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389e3000-3349-44c2-bf9f-27c4a8c247d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = OmegaConf.create({\n",
    "    \"data\": {\n",
    "        \"path\": data_path,\n",
    "        \"input_vars\": [\"CO2\", \"SO2\", \"CH4\", \"BC\", \"rsdt\"],\n",
    "        \"output_vars\": [\"tas\", \"pr\"],\n",
    "        \"train_ssps\": [\"ssp126\", \"ssp370\", \"ssp585\"],\n",
    "        \"test_ssp\": \"ssp245\",\n",
    "        \"target_member_id\": 0,\n",
    "        \"batch_size\": 4,\n",
    "        \"num_workers\": 4\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"lr\": 1e-3,\n",
    "        \"weight_decay\": 1e-5,\n",
    "        \"max_epochs\": 3,\n",
    "        \"early_stopping_patience\": 10,\n",
    "        \"gradient_clip_val\": 1.0,\n",
    "        \"accumulate_grad_batches\": 1\n",
    "    }\n",
    "})\n",
    "inputs = len(config.data['input_vars'])\n",
    "outputs = len(config.data['output_vars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88a7f6d-6faa-427e-80b2-8d3e1717433c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = ClimateEmulationDataModule(**config.data)\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25eae813-2739-4ef6-bab2-8adafd6cf17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = SimpleCNN(\n",
    "#     n_input_channels = inputs,\n",
    "#     n_output_channels = outputs\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a54d200-7847-4126-b45c-fc2fef7a3f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_input_channels=5,\n",
    "        n_output_channels=2,\n",
    "        hidden_channels=32\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv3d(n_input_channels, hidden_channels, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm3d(hidden_channels)\n",
    "        self.conv2 = nn.Conv3d(hidden_channels, hidden_channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm3d(hidden_channels)\n",
    "        self.conv3 = nn.Conv3d(hidden_channels, n_output_channels, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Add batch dimension if not present\n",
    "        if len(x.shape) == 4:\n",
    "            x = x.unsqueeze(0)  # Add batch dimension at the start\n",
    "        \n",
    "        # Rearrange from [B, D, C, H, W] to [B, C, D, H, W]\n",
    "        x = x.permute(0, 2, 1, 3, 4)\n",
    "        \n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.conv3(x)\n",
    "        \n",
    "        # Permute back to original format [B, D, C, H, W]\n",
    "        x = x.permute(0, 2, 1, 3, 4)\n",
    "        \n",
    "        x = x.squeeze(0)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6d6645-5132-4a21-9093-4de1a3d9cfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myLightningModule(pl.LightningModule):\n",
    "    def __init__(self, model: nn.Module, learning_rate: float):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.save_hyperparameters(ignore=[\"model\"])\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.normalizer = None\n",
    "        self.training_step_outputs = []\n",
    "        self.current_epoch_losses = []\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def on_fit_start(self):\n",
    "        self.normalizer = self.trainer.datamodule.normalizer\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y_true_norm = batch\n",
    "        y_pred_norm = self(x)\n",
    "        loss = self.criterion(y_pred_norm, y_true_norm)\n",
    "        \n",
    "        # Store loss for epoch end logging\n",
    "        self.current_epoch_losses.append(loss.item())\n",
    "        \n",
    "        # Log loss for progress bar\n",
    "        self.log(\"train/loss\", loss, prog_bar=True, batch_size=x.size(0))\n",
    "        return loss\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        # Calculate and print average loss for the epoch\n",
    "        avg_loss = np.mean(self.current_epoch_losses)\n",
    "        print(f\"\\nEpoch {self.current_epoch} - Average training loss: {avg_loss:.6f}\")\n",
    "        self.current_epoch_losses = []  # Reset for next epoch\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y_true_norm = batch\n",
    "        y_pred_norm = self(x)\n",
    "        loss = self.criterion(y_pred_norm, y_true_norm)\n",
    "        self.log(\"val/loss\", loss, prog_bar=True, batch_size=x.size(0))\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n",
    "        return optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbfe725-0876-421e-9ab2-3c30d5abf388",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = myNN(\n",
    "    n_input_channels=5,\n",
    "    n_output_channels=2,\n",
    "    hidden_channels=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11117bed-c03d-4303-8953-31497334db9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lightning_model = myLightningModule(model, learning_rate=1e-3)\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    accelerator=\"auto\",\n",
    "    devices=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d0ce82-ea51-46b4-90d3-5ab891b531ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(lightning_model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8257f50-0876-4a4a-a944-a89246ead10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "all_preds = []\n",
    "all_trues = []\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "for x, y_true in data_module.test_dataloader():\n",
    "    x = x.to(device)\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(x)\n",
    "    all_preds.append(y_pred.cpu().numpy())\n",
    "    all_trues.append(y_true.cpu().numpy())\n",
    "\n",
    "y_pred_np = np.concatenate(all_preds, axis=0)\n",
    "y_true_np = np.concatenate(all_trues, axis=0)\n",
    "\n",
    "lat_coords, lon_coords = data_module.get_coords()\n",
    "time_coords = np.arange(y_pred_np.shape[0])\n",
    "var_names = config.data['output_vars']\n",
    "\n",
    "submission_df = convert_predictions_to_kaggle_format(\n",
    "    y_pred_np, time_coords, lat_coords, lon_coords, var_names\n",
    ")\n",
    "submission_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9869b6f-31ff-4dc7-83a0-d983ad942a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_df = convert_predictions_to_kaggle_format(\n",
    "    y_true_np, time_coords, lat_coords, lon_coords, var_names\n",
    ")\n",
    "kaggle_val_score = kaggle_score(solution_df, submission_df, \"ID\")\n",
    "print(\"Kaggle metric score:\", kaggle_val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9979d237-93c2-452e-97d6-1a87f342fef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_df = convert_predictions_to_kaggle_format(\n",
    "    y_true_np, time_coords, lat_coords, lon_coords, var_names\n",
    ")\n",
    "kaggle_val_score = kaggle_score(solution_df, submission_df, \"ID\")\n",
    "print(\"Kaggle metric score:\", kaggle_val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9e0d7dfd-f3c5-42b1-9e5a-dc892d38cd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cd0482-81da-4121-9b57-126e7a38e079",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
